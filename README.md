1) scraper.py - прописан функционал, чтобы вытягивать информацию о объявлениях с указанного количества страниц. Напрмер передадим url первой страницы, скрипт вытянет 
15 url объявлений с первой страницы и соберет информацию о недвижимостях из этих 15 объявлениях. И так, циклом пройдется по тому количеству страниц, которое мы укажем. 

2) extract_info.py - тут прописан функционал для скрапинга информации со страницы. В scraper.py мы используем фунции для скрапинга из extract_info. 

3) data_qual.py - преобразовывает вытянутые с сайта данные - передадим json с непричесанными данными (напр. 13 000 kč), а на выходе получим json, который можно будет отправлять в базу данных. 

4) pg_insert_data.py - берет причесанный json, присоединяется к нашей базе данных и загружает туда объявления

5) create_request_llm.py - делает запросы в ЛЛМ. На входе берет схему нашей базы данных и запрос пользователя, а на выходе дает SQL запрос, чтобы получить нужные данные из нашей БД

6) main.py - берет на вход запрос пользователя, просит create_request_llm.py создать нужный SQL запрос и обращается к базе данных, чтобы достать нужные пользователю данные 